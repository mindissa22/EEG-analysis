{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking EEG code\n",
    "\n",
    "Some reference code (to be checked):\n",
    "\n",
    "- https://github.com/AliAmini93/ADHDeepNet/tree/main\n",
    "\n",
    "**ADHD data**: https://ieee-dataport.org/open-access/eeg-data-adhd-control-children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Dataframe `adhd_df` will contain EEG data for all patients diagnosed with ADHD (for the 19 electrodes), plus one column with the ID of the patient. \n",
    "\n",
    "Dataframe `control_df` will be the equivalent for the control patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "from pathlib import Path\n",
    "import scipy.io as sio\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = Path.home() / Path(\"MyData/EEG_ADHD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel labels and electrode positions\n",
    "channel_labels = {\n",
    "    0: \"Fp1\",\n",
    "    1: \"Fp2\",\n",
    "    2: \"F3\",\n",
    "    3: \"F4\",\n",
    "    4: \"C3\",\n",
    "    5: \"C4\",\n",
    "    6: \"P3\",\n",
    "    7: \"P4\",\n",
    "    8: \"O1\",\n",
    "    9: \"O2\",\n",
    "    10: \"F7\",\n",
    "    11: \"F8\",\n",
    "    12: \"T7\",\n",
    "    13: \"T8\",\n",
    "    14: \"P7\",\n",
    "    15: \"P8\",\n",
    "    16: \"Fz\",\n",
    "    17: \"Cz\",\n",
    "    18: \"Pz\",\n",
    "}\n",
    "\n",
    "electrode_positions = {\n",
    "    \"Fp1\": (-18, 0.511, 0.95, 0.309, -0.0349, 18, -2, 1),\n",
    "    \"Fp2\": (18, 0.511, 0.95, -0.309, -0.0349, -18, -2, 1),\n",
    "    \"F7\": (-54, 0.511, 0.587, 0.809, -0.0349, 54, -2, 1),\n",
    "    \"F3\": (-39, 0.333, 0.673, 0.545, 0.5, 39, 30, 1),\n",
    "    \"Fz\": (0, 0.256, 0.719, 0, 0.695, 0, 44, 1),\n",
    "    \"F4\": (39, 0.333, 0.673, -0.545, 0.5, -39, 30, 1),\n",
    "    \"F8\": (54, 0.511, 0.587, -0.809, -0.0349, -54, -2, 1),\n",
    "    \"T7\": (-90, 0.511, 6.12e-17, 0.999, -0.0349, 90, -2, 1),\n",
    "    \"C3\": (-90, 0.256, 4.4e-17, 0.719, 0.695, 90, 44, 1),\n",
    "    \"Cz\": (90, 0, 3.75e-33, -6.12e-17, 1, -90, 90, 1),\n",
    "    \"C4\": (90, 0.256, 4.4e-17, -0.719, 0.695, -90, 44, 1),\n",
    "    \"T8\": (90, 0.511, 6.12e-17, -0.999, -0.0349, -90, -2, 1),\n",
    "    \"P7\": (-126, 0.511, -0.587, 0.809, -0.0349, 126, -2, 1),\n",
    "    \"P3\": (-141, 0.333, -0.673, 0.545, 0.5, 141, 30, 1),\n",
    "    \"Pz\": (180, 0.256, -0.719, -8.81e-17, 0.695, -180, 44, 1),\n",
    "    \"P4\": (141, 0.333, -0.673, -0.545, 0.5, -141, 30, 1),\n",
    "    \"P8\": (126, 0.511, -0.587, -0.809, -0.0349, -126, -2, 1),\n",
    "    \"O1\": (-162, 0.511, -0.95, 0.309, -0.0349, 162, -2, 1),\n",
    "    \"O2\": (162, 0.511, -0.95, -0.309, -0.0349, -162, -2, 1),\n",
    "}\n",
    "\n",
    "# Sampling Frequency Hz\n",
    "Sampling_Frequency = 128\n",
    "\n",
    "# Set the chunk size\n",
    "chunk_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(df, chunk_size, initial_chunk_number=0):\n",
    "    # Calculate the number of full chunks\n",
    "    n_chunks = len(df) // chunk_size\n",
    "    chunks = []\n",
    "\n",
    "    # Split into chunks and keep track of the chunk number\n",
    "    for i in range(n_chunks):\n",
    "        chunk = df.iloc[i * chunk_size : (i + 1) * chunk_size].copy()  # Get the chunk\n",
    "        chunk[\"chunk_number\"] = (\n",
    "            initial_chunk_number + i\n",
    "        )  # Add the chunk number as a new column\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    # Concatenate the chunks back together\n",
    "    return pd.concat(chunks, ignore_index=True), n_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dirs):\n",
    "    data_list = []\n",
    "    chunked_data_list = []\n",
    "\n",
    "    chunk_index = 0\n",
    "    for directory in data_dirs:\n",
    "        # print(f\"Loading data from {directory}\")\n",
    "\n",
    "        for filepath in directory.glob(\"*.mat\"):\n",
    "            mat = sio.loadmat(filepath)\n",
    "            key = list(mat.keys())[-1]  # Get the last key (the id of the patient)\n",
    "            eeg_data = mat[key]\n",
    "\n",
    "            # Convert the EEG data to a DataFrame\n",
    "            # Assuming the EEG data is a 2D array (time x channels)\n",
    "            df = pd.DataFrame(eeg_data)\n",
    "            df = df.rename(columns=channel_labels)\n",
    "            # Add a column to identify the source\n",
    "            df[\"subject_id\"] = key\n",
    "\n",
    "            # print(f\"Loaded data for patient {key}; chunks start at {chunk_index}\")\n",
    "            chucked_df, chunks = split_into_chunks(df, chunk_size, chunk_index)\n",
    "            chunk_index += chunks\n",
    "\n",
    "            # Append the DataFrame to the list\n",
    "            data_list.append(df)\n",
    "            chunked_data_list.append(chucked_df)\n",
    "\n",
    "        # Concatenate all DataFrames in the list into a single DataFrame\n",
    "        full_eeg_df = pd.concat(data_list, ignore_index=True)\n",
    "        chunked_eeg_df = pd.concat(chunked_data_list, ignore_index=True)\n",
    "\n",
    "    return full_eeg_df, chunked_eeg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adhd_dir1 = data_dir / Path(\"ADHD_part1\")\n",
    "adhd_dir2 = data_dir / Path(\"ADHD_part2\")\n",
    "adhd_df, adhd_chunks_df = load_data([adhd_dir1, adhd_dir2])\n",
    "\n",
    "control_dir1 = data_dir / Path(\"Control_part1\")\n",
    "control_dir2 = data_dir / Path(\"Control_part2\")\n",
    "control_df, control_chunks_df = load_data([control_dir1, control_dir2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some sanity checks on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ADHD subjects: 61\n",
      "Number of Control subjects: 60\n",
      "Number of subjects in both groups: 0\n",
      "ADHD - total number of data points: 1,207,069\n",
      "ADHD - total number of chunks of size 512: 2330\n",
      "Control - total number of data points: 959,314\n",
      "Control - total number of chunks of size 512: 1843\n"
     ]
    }
   ],
   "source": [
    "adhd_subjects = adhd_df[\"subject_id\"].unique()\n",
    "control_subjects = control_df[\"subject_id\"].unique()\n",
    "intersection = [item for item in adhd_subjects if item in control_subjects]\n",
    "\n",
    "\n",
    "num_patients = len(adhd_subjects) + len(control_subjects)\n",
    "num_data_points = adhd_df.shape[0] + control_df.shape[0]\n",
    "num_chunks = 0\n",
    "num_chunks2 = 0\n",
    "\n",
    "print(f\"Number of ADHD subjects: {len(adhd_subjects)}\")\n",
    "print(f\"Number of Control subjects: {len(control_subjects)}\")\n",
    "print(f\"Number of subjects in both groups: {len(intersection)}\")\n",
    "\n",
    "# print(adhd_df.info())\n",
    "# print(control_df.info())\n",
    "\n",
    "# print(adhd_df.describe())\n",
    "# print(control_df.describe())\n",
    "\n",
    "chunck_size = 512\n",
    "\n",
    "num_chunks = 0\n",
    "for patient in adhd_subjects:\n",
    "    data_points = adhd_df[adhd_df[\"subject_id\"] == patient].shape[0]\n",
    "    num_chunks += data_points // chunck_size\n",
    "\n",
    "print(f\"ADHD - total number of data points: {adhd_df.shape[0]:,}\")\n",
    "print(f\"ADHD - total number of chunks of size {chunck_size}: {num_chunks}\")\n",
    "\n",
    "num_chunks = 0\n",
    "for patient in control_subjects:\n",
    "    data_points = control_df[control_df[\"subject_id\"] == patient].shape[0]\n",
    "    num_chunks += data_points // chunck_size\n",
    "\n",
    "print(f\"Control - total number of data points: {control_df.shape[0]:,}\")\n",
    "print(f\"Control - total number of chunks of size {chunck_size}: {num_chunks}\")\n",
    "\n",
    "# adhd_df[adhd_df['subject_id']==adhd_subjects[0]].drop(columns=['subject_id']).plot(subplots=True, figsize=(10, 10), title='ADHD for subject ' + adhd_subjects[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "ADHD subjects\n",
      "*****\n",
      "Subject v36p has 17401 data points\n",
      "Subject v20p has 35328 data points\n",
      "Subject v40p has 20097 data points\n",
      "Subject v21p has 16574 data points\n",
      "Subject v6p has 17561 data points\n",
      "Subject v173 has 24241 data points\n",
      "Subject v37p has 9286 data points\n",
      "Subject v10p has 14304 data points\n",
      "Subject v30p has 21663 data points\n",
      "Subject v1p has 12258 data points\n",
      "Subject v27p has 28880 data points\n",
      "Subject v31p has 11679 data points\n",
      "Subject v12p has 17604 data points\n",
      "Subject v28p has 27612 data points\n",
      "Subject v24p has 16385 data points\n",
      "Subject v3p has 33570 data points\n",
      "Subject v32p has 18049 data points\n",
      "Subject v33p has 29217 data points\n",
      "Subject v25p has 9894 data points\n",
      "Subject v29p has 24193 data points\n",
      "Subject v18p has 25003 data points\n",
      "Subject v22p has 12100 data points\n",
      "Subject v34p has 19555 data points\n",
      "Subject v14p has 17562 data points\n",
      "Subject v38p has 24695 data points\n",
      "Subject v39p has 18177 data points\n",
      "Subject v8p has 15776 data points\n",
      "Subject v15p has 43252 data points\n",
      "Subject v35p has 15305 data points\n",
      "Subject v19p has 23063 data points\n",
      "Subject v177 has 16697 data points\n",
      "Subject v215 has 21372 data points\n",
      "Subject v200 has 12739 data points\n",
      "Subject v213 has 12353 data points\n",
      "Subject v206 has 20173 data points\n",
      "Subject v204 has 20456 data points\n",
      "Subject v238 has 9852 data points\n",
      "Subject v198 has 19621 data points\n",
      "Subject v263 has 18657 data points\n",
      "Subject v288 has 20115 data points\n",
      "Subject v274 has 17323 data points\n",
      "Subject v270 has 23681 data points\n",
      "Subject v265 has 18389 data points\n",
      "Subject v254 has 10477 data points\n",
      "Subject v286 has 11465 data points\n",
      "Subject v279 has 20134 data points\n",
      "Subject v250 has 13853 data points\n",
      "Subject v244 has 39030 data points\n",
      "Subject v246 has 21307 data points\n",
      "Subject v284 has 15383 data points\n",
      "Subject v181 has 10668 data points\n",
      "Subject v234 has 34191 data points\n",
      "Subject v209 has 30273 data points\n",
      "Subject v196 has 13395 data points\n",
      "Subject v236 has 13502 data points\n",
      "Subject v183 has 18591 data points\n",
      "Subject v227 has 28080 data points\n",
      "Subject v179 has 12673 data points\n",
      "Subject v190 has 15465 data points\n",
      "Subject v231 has 19713 data points\n",
      "Subject v219 has 27157 data points\n",
      "*****\n",
      "Control subjects\n",
      "*****\n",
      "Subject v57p has 14692 data points\n",
      "Subject v41p has 12500 data points\n",
      "Subject v56p has 14139 data points\n",
      "Subject v60p has 12929 data points\n",
      "Subject v114 has 13304 data points\n",
      "Subject v51p has 7983 data points\n",
      "Subject v115 has 15651 data points\n",
      "Subject v47p has 10864 data points\n",
      "Subject v116 has 19301 data points\n",
      "Subject v112 has 15943 data points\n",
      "Subject v107 has 19794 data points\n",
      "Subject v113 has 15574 data points\n",
      "Subject v46p has 9823 data points\n",
      "Subject v111 has 15310 data points\n",
      "Subject v50p has 16239 data points\n",
      "Subject v110 has 16549 data points\n",
      "Subject v45p has 10871 data points\n",
      "Subject v109 has 16044 data points\n",
      "Subject v53p has 19122 data points\n",
      "Subject v108 has 19026 data points\n",
      "Subject v49p has 16769 data points\n",
      "Subject v48p has 10452 data points\n",
      "Subject v52p has 13883 data points\n",
      "Subject v44p has 11393 data points\n",
      "Subject v59p has 16513 data points\n",
      "Subject v43p has 12750 data points\n",
      "Subject v55p has 14282 data points\n",
      "Subject v54p has 19234 data points\n",
      "Subject v42p has 16704 data points\n",
      "Subject v58p has 13918 data points\n",
      "Subject v149 has 17098 data points\n",
      "Subject v302 has 17841 data points\n",
      "Subject v129 has 11208 data points\n",
      "Subject v303 has 19222 data points\n",
      "Subject v117 has 25659 data points\n",
      "Subject v300 has 25985 data points\n",
      "Subject v310 has 17793 data points\n",
      "Subject v304 has 13400 data points\n",
      "Subject v305 has 22273 data points\n",
      "Subject v307 has 22807 data points\n",
      "Subject v298 has 17782 data points\n",
      "Subject v299 has 22260 data points\n",
      "Subject v138 has 12488 data points\n",
      "Subject v306 has 18301 data points\n",
      "Subject v121 has 16377 data points\n",
      "Subject v134 has 13359 data points\n",
      "Subject v120 has 12033 data points\n",
      "Subject v308 has 17025 data points\n",
      "Subject v297 has 13697 data points\n",
      "Subject v123 has 14550 data points\n",
      "Subject v309 has 24818 data points\n",
      "Subject v133 has 15073 data points\n",
      "Subject v127 has 14721 data points\n",
      "Subject v118 has 12007 data points\n",
      "Subject v131 has 16686 data points\n",
      "Subject v125 has 15378 data points\n",
      "Subject v143 has 15607 data points\n",
      "Subject v140 has 17187 data points\n",
      "Subject v151 has 20914 data points\n",
      "Subject v147 has 14209 data points\n"
     ]
    }
   ],
   "source": [
    "print(\"*****\\nADHD subjects\\n*****\")\n",
    "for subject in adhd_subjects:\n",
    "    print(\n",
    "        f\"Subject {subject} has {adhd_df[adhd_df['subject_id']==subject].shape[0]} data points\"\n",
    "    )\n",
    "\n",
    "print(\"*****\\nControl subjects\\n*****\")\n",
    "for subject in control_subjects:\n",
    "    print(\n",
    "        f\"Subject {subject} has {control_df[control_df['subject_id']==subject].shape[0]} data points\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject = adhd_subjects[0]\n",
    "# df = adhd_df[adhd_df['subject_id']==subject].drop(columns=['subject_id'])\n",
    "# df.plot(subplots=True, figsize=(10, 10), title='ADHD for subject ' + subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organise data into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4173\n"
     ]
    }
   ],
   "source": [
    "# Let's put all the data together (we will use the \"chunked\" data)\n",
    "adhd_chunks_df[\"label\"] = \"ADHD\"\n",
    "control_chunks_df[\"label\"] = \"Control\"\n",
    "\n",
    "# we need to \"renumber\" the chunks for the control data so that they are continuous with the ADHD data\n",
    "control_chunks_df[\"chunk_number\"] += adhd_chunks_df[\"chunk_number\"].max() + 1\n",
    "\n",
    "all_data_df = pd.concat([adhd_chunks_df, control_chunks_df], ignore_index=True)\n",
    "\n",
    "print(all_data_df[\"chunk_number\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4173, 4)\n"
     ]
    }
   ],
   "source": [
    "chunks_df = (\n",
    "    all_data_df[[\"chunk_number\", \"subject_id\", \"label\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "chunks_df = pd.get_dummies(chunks_df, columns=[\"label\"])\n",
    "print(chunks_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4173, 19, 512)\n"
     ]
    }
   ],
   "source": [
    "# Let's reshape the data into a 3D array (chunks x channels x samples)\n",
    "import einops\n",
    "\n",
    "raw_data = all_data_df.drop(columns=[\"subject_id\", \"label\"])\n",
    "# raw_data.info()\n",
    "\n",
    "# 1. Extract the data (excluding the 'chunk_number' column)\n",
    "raw_data = raw_data.iloc[:, :-1].values  # shape will be (#tot_samples, 19)\n",
    "\n",
    "# 2. Reshape the data into a 3D array\n",
    "num_chunks = chunks_df.shape[0]\n",
    "eeg_data = einops.rearrange(\n",
    "    raw_data,\n",
    "    \"(chunks points) electrodes -> chunks electrodes points\",\n",
    "    chunks=num_chunks,\n",
    "    points=chunk_size,\n",
    ")\n",
    "\n",
    "print(eeg_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3695, 1, 19, 512) (3695, 2) (3695, 4)\n",
      "(478, 1, 19, 512) (478, 2) (478, 4)\n"
     ]
    }
   ],
   "source": [
    "X = eeg_data\n",
    "# expand the dimensions to make it compatible with the Conv1D layer in Keras\n",
    "# the new shape will be (#tot_samples, 1, 19, 512)\n",
    "X = np.expand_dims(X, axis=1)\n",
    "\n",
    "y = chunks_df[[\"label_ADHD\", \"label_Control\"]].values\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Generate a random permutation of the indices\n",
    "indices = np.random.permutation(len(X))\n",
    "\n",
    "# 2. Use the first 80% of the indices for the training set\n",
    "# train_size = int(0.8 * len(X))\n",
    "train_size = 3695\n",
    "\n",
    "# 3. Split the indices into train and test sets\n",
    "train_indices = indices[:train_size]\n",
    "test_indices = indices[train_size:]\n",
    "\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "chunks_train = chunks_df.iloc[train_indices].values\n",
    "chunks_test = chunks_df.iloc[test_indices].values\n",
    "\n",
    "print(X_train.shape, y_train.shape, chunks_train.shape)\n",
    "print(X_test.shape, y_test.shape, chunks_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all labels to proper one-hot encoding (integers instead of booleans) - not needed\n",
    "# y_train = y_train.astype(int)\n",
    "# y_test = y_test.astype(int)\n",
    "\n",
    "Group_train = chunks_train[:, [0, 1]]\n",
    "Group_test = chunks_test[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 2072 ADHD /  1623 Control\n",
      "Test set: 258 ADHD /  220 Control\n"
     ]
    }
   ],
   "source": [
    "label_distr_counts_train = np.sum(y_train, axis=0)\n",
    "label_distr_counts_test = np.sum(y_test, axis=0)\n",
    "\n",
    "print(f\"Training set: {label_distr_counts_train[0]} ADHD /  {label_distr_counts_train[1]} Control\")\n",
    "print(f\"Test set: {label_distr_counts_test[0]} ADHD /  {label_distr_counts_test[1]} Control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyriemann.utils.viz import plot_confusion_matrix\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def subject_classification1(y_true, y_pred, group, calculate_type=\"max_vote\"):\n",
    "    \"\"\"\n",
    "    y_pred should be the output of 'model.predict' using 2 nodes in the dense layer and softmax activation.\n",
    "    y_true should be in categorical mode.\n",
    "    \"\"\"\n",
    "\n",
    "    # Categorical to normal labeling\n",
    "    # NB: 0 will indicate ADHD and 1 will indicate Control (TO BE CHECKED)\n",
    "    y_true = y_true.argmax(axis=-1)    \n",
    "    probability = np.array(y_pred)\n",
    "    # Turn predictions to one hot\n",
    "    max_indices = np.argmax(y_pred, axis=1)\n",
    "    prediction_one_hot = np.zeros((y_pred.shape[0], y_pred.shape[1]))\n",
    "    prediction_one_hot[np.arange(y_pred.shape[0]), max_indices] = 1\n",
    "    \n",
    "    max_vote = []\n",
    "    subject_target = []\n",
    "\n",
    "    # Combine prediction probabilities and subject labels\n",
    "    probability = np.concatenate((probability, group), axis=1)\n",
    "    # Convert combined array to DataFrame\n",
    "    probability_df = pd.DataFrame(probability, columns=['ADHD', 'Control', 'Subject'])\n",
    "    # Make sure the prediction columns are float\n",
    "    probability_df[['ADHD', 'Control']] = probability_df[['ADHD', 'Control']].astype(float)\n",
    "    # Compute mean of predictions per unique subject\n",
    "    mean_predictions_per_subject = probability_df.groupby('Subject').mean()\n",
    "    # Make sure the the groups are sorted by the grouping key (the subject id) after grouping\n",
    "    mean_predictions_per_subject = mean_predictions_per_subject.sort_index()\n",
    "    # Revert the DataFrame to a numpy array\n",
    "    mean_predictions_per_subject = mean_predictions_per_subject.to_numpy()\n",
    "    mean_ = mean_predictions_per_subject.argmax(axis=-1)\n",
    "\n",
    "    # Combine prediction classes and subject labels\n",
    "    prediction = np.concatenate((prediction_one_hot, group), axis=1)\n",
    "    # Convert combined array to DataFrame\n",
    "    prediction_df = pd.DataFrame(prediction, columns=['ADHD', 'Control', 'Subject'])\n",
    "    # Make sure the prediction columns are int\n",
    "    prediction_df[['ADHD', 'Control']] = prediction_df[['ADHD', 'Control']].astype(int)\n",
    "    # Compute total number a class was predicted per unique subject\n",
    "    sum_predictions_per_subject = prediction_df.groupby('Subject').sum()\n",
    "    # # Make sure the the groups are sorted by the grouping key (the subject id) after grouping\n",
    "    sum_predictions_per_subject = sum_predictions_per_subject.sort_index()\n",
    "    # Revert the DataFrame to a numpy array\n",
    "    sum_predictions_per_subject = sum_predictions_per_subject.to_numpy()\n",
    "    # sum_predictions_per_subject\n",
    "    max_vote = np.argmax(sum_predictions_per_subject, axis=1)\n",
    "    subject_target = np.array(y_true)\n",
    "\n",
    "    # # j = 0\n",
    "    # # unique, counts = np.unique(group, return_counts=True)\n",
    "    # # mean_ = np.zeros([len(unique), 2], dtype=\"float32\")\n",
    "    # # for i in range(len(unique)):\n",
    "    # #     for k in range(2):\n",
    "    # #         mean_[i][k] = np.mean(probability[j : j + counts[i] - 1, k])\n",
    "    # #     c = np.bincount(prediction[j : j + counts[i] - 1])\n",
    "    # #     max_vote.append(np.argmax(c))\n",
    "    # #     subject_traget.append(y_true[j])\n",
    "    # #     j = j + counts[i]\n",
    "    # # mean_ = mean_.argmax(axis=-1)\n",
    "    # # max_vote = np.array(max_vote)\n",
    "    # # subject_traget = np.array(subject_traget)\n",
    "\n",
    "    f2_max_vote = fbeta_score(subject_target, max_vote, beta=0.5, average=\"binary\")\n",
    "    f2_mean = fbeta_score(subject_target, mean_, beta=0.5, average=\"binary\")\n",
    "    acc_max_vote = np.mean(max_vote == subject_target)\n",
    "    acc_mean = np.mean(mean_ == subject_target)\n",
    "    if calculate_type == 'max_vote':\n",
    "        return acc_max_vote, f2_max_vote\n",
    "    elif calculate_type == 'mean':\n",
    "        return acc_mean, f2_mean\n",
    "    else:\n",
    "        raise ValueError('You have NOT entered an accurate type!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_time_series_data(data, label, sigma, magnification_factor):\n",
    "    augmented_data = []\n",
    "    augmented_label = []\n",
    "\n",
    "    n, _, electrodes, time_steps = data.shape\n",
    "    if sigma[0] == 0 and magnification_factor[0] == 0:\n",
    "        return data, label\n",
    "    else:\n",
    "        # loop through each sample\n",
    "        for i in range(n):\n",
    "            for s in sigma:\n",
    "                for m in magnification_factor:\n",
    "                    # generate noise with the given sigma\n",
    "                    noise = np.random.normal(0, s, (electrodes, time_steps))\n",
    "\n",
    "                    # augment the data with the noise and magnification factor\n",
    "                    augmented_sample = data[i, :, :, :] + noise * m\n",
    "                    augmented_data.append(augmented_sample)\n",
    "\n",
    "                    # augment the label with the same label\n",
    "                    augmented_label.append(label[i])\n",
    "        # change list to numpy array\n",
    "        augmented_data, augmented_label = np.array(augmented_data), np.array(\n",
    "            augmented_label\n",
    "        )\n",
    "\n",
    "        return np.concatenate((data, augmented_data)), np.concatenate(\n",
    "            (label, augmented_label)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# from itertools import combinations\n",
    "\n",
    "def generate_combinations(magnification_factor, sigma):\n",
    "    result = [{\"magnification_factor\": [0], \"sigma\": [0]}]\n",
    "    for i in range(1, 4):\n",
    "        for m_comb in itertools.combinations(magnification_factor, i):\n",
    "            for sigma_comb in itertools.combinations(sigma, i):\n",
    "                result.append(\n",
    "                    {\"magnification_factor\": list(m_comb), \"sigma\": list(sigma_comb)}\n",
    "                )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_classification(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_pred should be the output of 'model.predict' using 2 nodes in the dense layer and softmax activation.\n",
    "    y_true should be in categorical mode.\n",
    "    \"\"\"\n",
    "    preds = y_pred.argmax(axis=-1)\n",
    "    acc = np.mean(preds == y_true.argmax(axis=-1))\n",
    "    f2 = fbeta_score(y_true.argmax(axis=-1), preds, beta=0.5, average=\"binary\")\n",
    "    return acc, f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassWeightSoftmax(y):\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight=\"balanced\", classes=np.unique(Y_train), y=Y_train\n",
    "    )\n",
    "    class_weights = dict(zip(np.unique(Y_train), class_weights))\n",
    "    class_weights[0] = int(10 * round(class_weights[0], 1))\n",
    "    class_weights[1] = int(10 * round(class_weights[1], 1))\n",
    "    class_weight = [{0: 1, 1: class_weights[0]}, {0: 1, 1: class_weights[1]}]\n",
    "    print(\"The Class Weight is:\", class_weight)\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GridSearchCV\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout, multiply, LSTM\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# from tensorflow.keras.optimizers import Adam, Adamax\n",
    "# from tensorflow.keras.optimizers.experimental import AdamW\n",
    "from tensorflow.keras.optimizers import Adam, Adamax, AdamW\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "import math\n",
    "import gc\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def TactileNet(\n",
    "    nb_classes=2,\n",
    "    Chans=19,\n",
    "    Samples=512,\n",
    "    kernLength=16,\n",
    "    F2=64,\n",
    "    F1=64,\n",
    "    D=4,\n",
    "    dropoutRate=0.5,\n",
    "    dropoutType=\"Dropout\",\n",
    "    norm_rate=0.25,\n",
    "    Dense_nodes=16,\n",
    "    optimizer_type=\"Adam\",\n",
    "    lr=0.001,\n",
    "    **kwargs\n",
    "):\n",
    "\n",
    "    if dropoutType == \"SpatialDropout2D\":\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == \"Dropout\":\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"dropoutType must be one of SpatialDropout2D \"\n",
    "            \"or Dropout, passed as a string.\"\n",
    "        )\n",
    "    # EEGNet alike part\n",
    "    input1 = Input(shape=(1, Chans, Samples))\n",
    "    block1 = Conv2D(\n",
    "        F1,\n",
    "        (1, kernLength),\n",
    "        padding=\"same\",\n",
    "        input_shape=(1, Chans, Samples),\n",
    "        use_bias=False,\n",
    "    )(input1)\n",
    "    block1 = BatchNormalization(axis=1, trainable=True)(block1)\n",
    "    block1 = DepthwiseConv2D(\n",
    "        (Chans, 1),\n",
    "        use_bias=False,\n",
    "        depth_multiplier=D,\n",
    "        depthwise_constraint=max_norm(norm_rate),\n",
    "    )(block1)\n",
    "    block1 = BatchNormalization(axis=1, trainable=True)(block1)\n",
    "    block1 = Activation(\"elu\")(block1)\n",
    "    block1 = AveragePooling2D((1, 2))(block1)\n",
    "    block1 = dropoutType(dropoutRate)(block1)\n",
    "\n",
    "    ###############################################\n",
    "    # first tower\n",
    "    sub_block1 = Conv2D(64, (1, 1), padding=\"same\", use_bias=False)(block1)\n",
    "    sub_block1 = SeparableConv2D(128, (1, 128), padding=\"same\", use_bias=False)(\n",
    "        sub_block1\n",
    "    )\n",
    "    sub_block1 = AveragePooling2D((1, 2), padding=\"same\")(sub_block1)\n",
    "    # second tower\n",
    "    sub_block2 = Conv2D(16, (1, 1), padding=\"same\", use_bias=False)(block1)\n",
    "    sub_block2 = SeparableConv2D(32, (1, 256), padding=\"same\", use_bias=False)(\n",
    "        sub_block2\n",
    "    )\n",
    "    sub_block2 = AveragePooling2D((1, 2), padding=\"same\")(sub_block2)\n",
    "    # third tower\n",
    "    sub_block3 = Conv2D(64, (1, 1), padding=\"same\", strides=(1, 2), use_bias=False)(\n",
    "        block1\n",
    "    )\n",
    "    # forth tower\n",
    "    sub_block4 = AveragePooling2D((1, 2), padding=\"same\")(block1)\n",
    "    sub_block4 = Conv2D(32, (1, 1), padding=\"same\", use_bias=False)(sub_block4)\n",
    "    # concatenation\n",
    "    concat = concatenate([sub_block1, sub_block2, sub_block4, sub_block3], axis=1)\n",
    "\n",
    "    # last tower\n",
    "    block2 = BatchNormalization(axis=1, trainable=True)(concat)\n",
    "    block2 = Activation(\"elu\")(block2)\n",
    "    # SENEt block\n",
    "    squeeze1 = GlobalAveragePooling2D()(block2)\n",
    "    excitation1 = Dense(Dense_nodes, activation=\"relu\")(squeeze1)\n",
    "    excitation1 = Dense(256, activation=\"sigmoid\")(excitation1)\n",
    "    block2 = Permute(dims=(2, 3, 1))(block2)\n",
    "    excitation1 = multiply([block2, excitation1])\n",
    "    excitation1 = Permute(dims=(3, 1, 2))(excitation1)\n",
    "\n",
    "    block2 = SeparableConv2D(256, (1, 64), padding=\"same\", use_bias=False)(excitation1)\n",
    "    block2 = BatchNormalization(axis=1, trainable=True)(block2)\n",
    "    block2 = Activation(\"elu\")(block2)\n",
    "    # SENEt block\n",
    "    squeeze2 = GlobalAveragePooling2D()(block2)\n",
    "    excitation2 = Dense(Dense_nodes, activation=\"relu\")(squeeze2)\n",
    "    excitation2 = Dense(256, activation=\"sigmoid\")(excitation2)\n",
    "    block2 = Permute(dims=(2, 3, 1))(block2)\n",
    "    excitation2 = multiply([block2, excitation2])\n",
    "    excitation2 = Permute(dims=(3, 1, 2))(excitation2)\n",
    "\n",
    "    block2 = dropoutType(dropoutRate)(excitation2)\n",
    "\n",
    "    GB = GlobalAveragePooling2D()(block2)\n",
    "    denselayer = Dense(nb_classes, name=\"denselayer\", kernel_constraint=max_norm(norm_rate))(GB)\n",
    "    softmax = Activation(\"softmax\", name=\"softmax\")(denselayer)\n",
    "    if optimizer_type == \"Adam\":\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "    if optimizer_type == \"Adamax\":\n",
    "        optimizer = Adamax(learning_rate=lr)\n",
    "    if optimizer_type == \"AdamW\":\n",
    "        optimizer = AdamW(learning_rate=lr)\n",
    "    model = Model(inputs=input1, outputs=softmax)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-09-01 21:00:35.632295: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2024-09-01 21:00:35.632314: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-09-01 21:00:35.632324: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-09-01 21:00:35.632345: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-01 21:00:35.632356: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,864</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ depthwise_conv2d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling2d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ separable_conv2d    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ separable_conv2d_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling2d_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ separable_conv2d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling2d_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ separable_conv2d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ average_pooling2… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ average_pooling2… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ average_pooling2… │\n",
       "│                     │                   │            │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,112</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ permute[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ separable_conv2d_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">81,920</span> │ permute_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ separable_conv2d… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,112</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ permute_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ permute_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denselayer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ denselayer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m19\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m19\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m19\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ depthwise_conv2d    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │      \u001b[38;5;34m4,864\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)   │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ depthwise_conv2d… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling2d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m,     │     \u001b[38;5;34m16,384\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m,     │      \u001b[38;5;34m4,096\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ separable_conv2d    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │     \u001b[38;5;34m16,384\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ separable_conv2d_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m,     │      \u001b[38;5;34m4,608\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling2d_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ separable_conv2d… │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_pooling2d_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ separable_conv2d… │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m,     │      \u001b[38;5;34m8,192\u001b[0m │ average_pooling2… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m,     │     \u001b[38;5;34m16,384\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ average_pooling2… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ average_pooling2… │\n",
       "│                     │                   │            │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m4,112\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute (\u001b[38;5;33mPermute\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m4,352\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ permute[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_1 (\u001b[38;5;33mPermute\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ separable_conv2d_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │     \u001b[38;5;34m81,920\u001b[0m │ permute_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │      \u001b[38;5;34m1,024\u001b[0m │ separable_conv2d… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m4,112\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_2 (\u001b[38;5;33mPermute\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m4,352\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ permute_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mMultiply\u001b[0m)          │ \u001b[38;5;34m256\u001b[0m)              │            │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ permute_3 (\u001b[38;5;33mPermute\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ permute_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ denselayer (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m514\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ denselayer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,626</span> (682.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m174,626\u001b[0m (682.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">172,962</span> (675.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m172,962\u001b[0m (675.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> (6.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,664\u001b[0m (6.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model = TactileNet()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the space of hyperparameters to search\n",
    "search_space = list()\n",
    "search_space.append(Categorical([8, 16, 32, 64], name=\"F1\"))\n",
    "search_space.append(Categorical([16, 32, 64, 128, 256], name=\"F2\"))\n",
    "search_space.append(Categorical([2, 4, 8], name=\"D\"))\n",
    "search_space.append(Categorical([32, 64, 128, 256, 512], name=\"kernLength\"))\n",
    "search_space.append(Categorical([8, 16, 32], name=\"Dense_nodes\"))\n",
    "search_space.append(Categorical([0.5, 1.0, 5.0, 10.0], name=\"norm_rate\"))\n",
    "search_space.append(Categorical([0.0001, 0.0005, 0.001, 0.005, 0.01], name=\"lr\"))\n",
    "search_space.append(Categorical([\"Adam\", \"Adamax\", \"AdamW\"], name=\"optimizer\"))\n",
    "search_space.append(Categorical([0.3, 0.4, 0.5], name=\"dropoutRate\"))\n",
    "search_space.append(Categorical([32, 64, 128], name=\"batch_size\"))\n",
    "\n",
    "\n",
    "# define the function used to evaluate a given configuration\n",
    "@use_named_args(search_space)\n",
    "def evaluate_model(**params):\n",
    "    sample_acc = []\n",
    "    sample_f2 = []\n",
    "    subject_acc = []\n",
    "    subject_f2 = []\n",
    "    sample_loss = []\n",
    "    ### Defining SKGF ###\n",
    "    #######################\n",
    "    # Callbacks #\n",
    "    # modelpath = \"./Bayesian Saved Model/model_{epoch:02d}_{val_loss:.2f}.keras\"\n",
    "    model_path = \"./Bayesian Saved Model/model.keras\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        model_path, monitor=\"val_accuracy\", verbose=1, save_best_only=True, mode=\"max\"\n",
    "    )\n",
    "    es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=15)\n",
    "    keras_reduce_lr = ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=10, min_lr=0.00005, verbose=2\n",
    "    )\n",
    "    callbacks = [checkpoint, es, keras_reduce_lr]\n",
    "    model = TactileNet(**params)\n",
    "    # Fitting ...\n",
    "    fit = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        verbose=2,\n",
    "        shuffle=True,\n",
    "        # epochs=100,\n",
    "        epochs=2, # changed to keep training short\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    del model, fit\n",
    "\n",
    "    ### Loading The Best Saved Model ###\n",
    "    saved_model = load_model(model_path)\n",
    "    \n",
    "    # Predict The model\n",
    "    test_predict = saved_model.predict(X_test)\n",
    "    test_loss, test_acc = saved_model.evaluate(X_test, y_test)\n",
    "    ######################################################################################################\n",
    "    print(\"test_loss\", test_loss)\n",
    "    print(\"test_acc\", test_acc)\n",
    "    ######################################################################################################\n",
    "\n",
    "    # Select the true labels for the (unique) subjects\n",
    "    _, indices = np.unique(Group_test[:, 1], return_index=True)\n",
    "    subject_true_pred = y_test[indices]\n",
    "\n",
    "    Group_test_labels = Group_test[:, 1].reshape(-1, 1)\n",
    "\n",
    "    sub_acc, sub_f2 = subject_classification1(\n",
    "        subject_true_pred, test_predict, Group_test_labels, calculate_type=\"max_vote\"\n",
    "    )\n",
    "    sam_acc, sam_f2 = sample_classification(y_test, test_predict)\n",
    "\n",
    "    # convert from a maximizing score to a minimizing score\n",
    "    return 1.0 - sam_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 21:00:36.515619: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "(0.896551724137931, 0.9504132231404959)\n",
      "(0.895397489539749, 0.9334763948497854)\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "DB_model_path = \"./Bayesian Saved Model/model.keras\"\n",
    "DB_saved_model = load_model(DB_model_path)\n",
    "\n",
    "# Select the true labels for the (unique) subjects\n",
    "_, indices = np.unique(Group_test[:, 1], return_index=True)\n",
    "DB_y_true = y_test[indices]\n",
    "\n",
    "DB_y_pred = DB_saved_model.predict(X_test)\n",
    "DB_group = Group_test[:, 1].reshape(-1, 1)\n",
    "\n",
    "DB_subj_res = subject_classification1(DB_y_true, DB_y_pred, DB_group, calculate_type=\"max_vote\")\n",
    "print(DB_subj_res)\n",
    "\n",
    "DB_sam_res = sample_classification(y_test, DB_y_pred)\n",
    "print(DB_sam_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46234, saving model to ./Bayesian Saved Model/model.keras\n",
      "29/29 - 61s - 2s/step - accuracy: 0.7396 - loss: 0.5227 - val_accuracy: 0.4623 - val_loss: 0.6746 - learning_rate: 5.0000e-04\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.46234 to 0.47280, saving model to ./Bayesian Saved Model/model.keras\n",
      "29/29 - 57s - 2s/step - accuracy: 0.8723 - loss: 0.3046 - val_accuracy: 0.4728 - val_loss: 0.6732 - learning_rate: 5.0000e-04\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4634 - loss: 0.6772\n",
      "test_loss 0.6731755137443542\n",
      "test_acc 0.47280335426330566\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.83891, saving model to ./Bayesian Saved Model/model.keras\n",
      "29/29 - 80s - 3s/step - accuracy: 0.7716 - loss: 0.4667 - val_accuracy: 0.8389 - val_loss: 0.6683 - learning_rate: 5.0000e-04\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.83891 to 0.88703, saving model to ./Bayesian Saved Model/model.keras\n",
      "29/29 - 77s - 3s/step - accuracy: 0.9234 - loss: 0.1953 - val_accuracy: 0.8870 - val_loss: 0.6416 - learning_rate: 5.0000e-04\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8906 - loss: 0.6435\n",
      "test_loss 0.6416162848472595\n",
      "test_acc 0.8870292901992798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.89749, saving model to ./Bayesian Saved Model/model.keras\n",
      "116/116 - 69s - 593ms/step - accuracy: 0.8249 - loss: 0.3985 - val_accuracy: 0.8975 - val_loss: 0.6238 - learning_rate: 5.0000e-04\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.89749\n",
      "116/116 - 65s - 559ms/step - accuracy: 0.9131 - loss: 0.2092 - val_accuracy: 0.8891 - val_loss: 0.3542 - learning_rate: 5.0000e-04\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8919 - loss: 0.6275\n",
      "test_loss 0.6238373517990112\n",
      "test_acc 0.8974895477294922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64435, saving model to ./Bayesian Saved Model/model.keras\n",
      "116/116 - 51s - 443ms/step - accuracy: 0.7513 - loss: 0.5184 - val_accuracy: 0.6444 - val_loss: 0.6768 - learning_rate: 1.0000e-04\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.64435 to 0.85774, saving model to ./Bayesian Saved Model/model.keras\n",
      "116/116 - 46s - 398ms/step - accuracy: 0.8842 - loss: 0.2831 - val_accuracy: 0.8577 - val_loss: 0.5864 - learning_rate: 1.0000e-04\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8616 - loss: 0.5867\n",
      "test_loss 0.5864286422729492\n",
      "test_acc 0.857740581035614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54393, saving model to ./Bayesian Saved Model/model.keras\n",
      "29/29 - 31s - 1s/step - accuracy: 0.8430 - loss: 0.3452 - val_accuracy: 0.5439 - val_loss: 4.3580 - learning_rate: 0.0100\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.54393 to 0.59414, saving model to ./Bayesian Saved Model/model.keras\n",
      "29/29 - 26s - 887ms/step - accuracy: 0.9456 - loss: 0.1286 - val_accuracy: 0.5941 - val_loss: 2.4837 - learning_rate: 0.0100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.5797 - loss: 2.5509\n",
      "test_loss 2.483736515045166\n",
      "test_acc 0.5941422581672668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59623, saving model to ./Bayesian Saved Model/model.keras\n",
      "58/58 - 46s - 799ms/step - accuracy: 0.8593 - loss: 0.3343 - val_accuracy: 0.5962 - val_loss: 1.0664 - learning_rate: 0.0100\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.59623 to 0.87448, saving model to ./Bayesian Saved Model/model.keras\n",
      "58/58 - 41s - 702ms/step - accuracy: 0.9499 - loss: 0.1295 - val_accuracy: 0.8745 - val_loss: 0.2643 - learning_rate: 0.0100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8746 - loss: 0.2603\n",
      "test_loss 0.2642769515514374\n",
      "test_acc 0.874476969242096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66109, saving model to ./Bayesian Saved Model/model.keras\n",
      "29/29 - 94s - 3s/step - accuracy: 0.8449 - loss: 0.3528 - val_accuracy: 0.6611 - val_loss: 0.6222 - learning_rate: 0.0010\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.66109 to 0.71130, saving model to ./Bayesian Saved Model/model.keras\n",
      "29/29 - 89s - 3s/step - accuracy: 0.9591 - loss: 0.1087 - val_accuracy: 0.7113 - val_loss: 0.5702 - learning_rate: 0.0010\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7102 - loss: 0.5730\n",
      "test_loss 0.5702220797538757\n",
      "test_acc 0.7112970948219299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48954, saving model to ./Bayesian Saved Model/model.keras\n",
      "29/29 - 71s - 2s/step - accuracy: 0.8300 - loss: 0.3825 - val_accuracy: 0.4895 - val_loss: 2.9816 - learning_rate: 0.0100\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.48954 to 0.72176, saving model to ./Bayesian Saved Model/model.keras\n",
      "29/29 - 65s - 2s/step - accuracy: 0.9405 - loss: 0.1520 - val_accuracy: 0.7218 - val_loss: 0.4922 - learning_rate: 0.0100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.7366 - loss: 0.4719\n",
      "test_loss 0.49224498867988586\n",
      "test_acc 0.7217572927474976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.89121, saving model to ./Bayesian Saved Model/model.keras\n",
      "58/58 - 53s - 916ms/step - accuracy: 0.8888 - loss: 0.2640 - val_accuracy: 0.8912 - val_loss: 0.3172 - learning_rate: 0.0100\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.89121\n",
      "58/58 - 45s - 768ms/step - accuracy: 0.9645 - loss: 0.0906 - val_accuracy: 0.8640 - val_loss: 1.5440 - learning_rate: 0.0100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9020 - loss: 0.2771\n",
      "test_loss 0.31717172265052795\n",
      "test_acc 0.8912134170532227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marco/miniconda3/envs/msc2024_eeg-tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.96234, saving model to ./Bayesian Saved Model/model.keras\n",
      "116/116 - 36s - 310ms/step - accuracy: 0.9012 - loss: 0.2282 - val_accuracy: 0.9623 - val_loss: 0.1135 - learning_rate: 0.0100\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.96234\n",
      "116/116 - 27s - 237ms/step - accuracy: 0.9591 - loss: 0.1141 - val_accuracy: 0.9289 - val_loss: 0.3176 - learning_rate: 0.0100\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9629 - loss: 0.1211\n",
      "test_loss 0.11351849883794785\n",
      "test_acc 0.9623430967330933\n",
      "Best Accuracy: 0.962\n",
      "Best Parameters: [16, 16, 8, 32, 8, 1.0, 0.01, 'AdamW', 0.5, 32]\n"
     ]
    }
   ],
   "source": [
    "# n_iteration = 100\n",
    "n_iteration = 10\n",
    "# perform optimization\n",
    "result = gp_minimize(evaluate_model, search_space, n_calls=n_iteration)\n",
    "# summarizing finding:\n",
    "print(\"Best Accuracy: %.3f\" % (1.0 - result.fun))\n",
    "print(\"Best Parameters: %s\" % (result.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# # Save the object to a file\n",
    "# with open('optimized_result.pkl', 'wb') as file:\n",
    "#     pickle.dump(result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "\n",
    "# # Save the entire workspace (all variables)\n",
    "# with open('workspace.pkl', 'wb') as f:\n",
    "#     dill.dump_session(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc2024_eeg-tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
